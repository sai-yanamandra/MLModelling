{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit14fe932158084f4fa556948bec6bf3e1",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "import sys\n",
    "print(sys.version)\n",
    "print(sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\repos\\\\APDSProject\\\\MLTuning\\\\datacleanup\\\\cvss_final_dataset.csv\")\n",
    "df.head()\n",
    "df.shape\n",
    "#df.info()\n",
    "#df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "remove_list = ['timestamp','data_type','data_format', 'data_version','data_meta_ASSIGNER','cvssV3_version','cvssV3_vectorString','cvssV2_version','cvssV2_vectorString']\n",
    "\n",
    "df.drop(remove_list,axis = 1, inplace = True)\n",
    "df.info\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CVSS3 Data Frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "cvss3_features = ['cvssV3_attackVector', 'cvssV3_attackComplexity', 'cvssV3_privilegesRequired', 'cvssV3_userInteraction', 'cvssV3_scope','cvssV3_confidentialityImpact', 'cvssV3_integrityImpact','cvssV3_availabilityImpact', 'cvssV3_baseScore', 'cvssV3_baseSeverity',      'baseMetricV3_exploitabilityScore', 'baseMetricV3_impactScore', ]\n",
    "\n",
    "cvss3_df = df[cvss3_features]\n",
    "\n",
    "cvss3_df.columns\n",
    "cvss3_df.info\n",
    "cvss3_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the numerical and categorical columns from CVSS Version 3 Featue Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_numerical_col = list(cvss3_df.describe().columns)\n",
    "cvssv3_categorical_col = list(set(cvss3_df.columns).difference(cvssv3_numerical_col))\n",
    "\n",
    "cvssv3_numerical_col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the features for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_categorical_col.remove('cvssV3_baseSeverity')\n",
    "cvssv3_categorical_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cvssv3_model_df= cvss3_df[cvssv3_categorical_col]\n",
    "cvssv3_model_df.shape\n",
    "\n",
    "#cvssv3_model_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_model_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform One Hot Encoding\n",
    "# https://towardsdatascience.com/encoding-categorical-features-21a2651a065c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_model_encoded_df = pd.get_dummies(cvssv3_model_df[cvssv3_categorical_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "cvssv3_model_encoded_df.describe()\n",
    "cvssv3_model_encoded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.concat([df['cvssV3_baseScore'], df_v3_model], axis=1)\n",
    "X = cvssv3_model_encoded_df\n",
    "X.shape\n",
    "#X.columns"
   ]
  },
  {
   "source": [
    "# Prepare the features with basic categorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CWE_df = pd.read_csv(\"D:\\\\repos\\\\APDSProject\\\\MLTuning\\\\datacollection\\\\CVSS-Base.csv\")\n",
    "\n",
    "CWE_df_new = CWE_df[CWE_df['Consequences'].notnull()]\n",
    "\n",
    "cvssv3_model_df['Consequences'] = CWE_df['Consequences']\n",
    "\n",
    "cvssv3_model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_model_df['Consequences'].unique\n",
    "\n",
    "[('DoS', 373),\n",
    " ('Bypass Protection Mechanism', 286),\n",
    " ('Read Application Data', 282),\n",
    " ('Execute Unauthorized Code or Commands', 248),\n",
    " ('Gain Privileges or Assume Identity', 234),\n",
    " (' Crash, Exit, or Restart', 181),\n",
    " ('Modify Memory', 172),\n",
    " ('Modify Application Data', 163),\n",
    " ('Varies by Context', 150),\n",
    " ('Unexpected State', 146),\n",
    " ('Read Memory', 129),\n",
    " ('Read Files or Directories', 100),\n",
    " ('Modify Files or Directories', 87),\n",
    " ('LIKELIHOOD', 86),\n",
    " ('Alter Execution Logic', 81),\n",
    " ('Reduce Maintainability', 77),\n",
    " ('Quality Degradation', 75),\n",
    " ('Hide Activities', 60),\n",
    " (' Resource Consumption (CPU)', 57),\n",
    " ('High', 57),\n",
    " (' Resource Consumption (Other)', 51),\n",
    " ('Reduce Reliability', 45),\n",
    " ('Authorization', 39),\n",
    " (' Resource Consumption (Memory)', 39),\n",
    " ('Reduce Performance', 36),\n",
    " (' Instability', 32),\n",
    " ('Accountability', 27),\n",
    " ('HighSCOPE', 14),\n",
    " ('Read MemorySCOPE', 10),\n",
    " (' Amplification', 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkConsequence(severity):\n",
    "   try:\n",
    "      if (\n",
    "             #Stability\n",
    "            ((severity.find(' Crash, Exit, or Restart') != -1) and\n",
    "             (severity.find('Instability') != -1)) or\n",
    "            \n",
    "            #Access\n",
    "            ((severity.find('Read Files or Directories') != -1) and \n",
    "             (severity.find('Modify Files or Directories') != -1))  or \n",
    "\n",
    "            #Authorization\n",
    "             ((severity.find('Execute Unauthorized Code or Commands') != -1) and \n",
    "             (severity.find('Gain Privileges or Assume Identity') != -1))\n",
    "         ):\n",
    "         return 1\n",
    "      else:\n",
    "         return 0   \n",
    "   except AttributeError:\n",
    "      return 0\n",
    "      \n",
    "cvssv3_model_df['Super_Severity_Score'] = cvssv3_model_df.apply(lambda row: checkConsequence(row['Consequences']),axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_model_df['Super_Severity_Score'].value_counts()\n",
    "#cvssv3_model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Super_Severity_Score'] = cvssv3_model_df['Super_Severity_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n",
    "#X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculateSeverityScore(row):\n",
    "    if (row['cvssV3_attackVector'] == \"NETWORK\" and (row['cvssV3_availabilityImpact'] == \"HIGH\" or row['cvssV3_availabilityImpact'] == \"HIGH\" ) and row['cvssV3_integrityImpact'] == \"HIGH\" and row['cvssV3_privilegesRequired'] == \"NONE\" and row['cvssV3_userInteraction'] == \"NONE\"):\n",
    "        return 'CRITICAL'\n",
    "    elif (row['cvssV3_attackVector'] == 'NETWORK' and row['cvssV3_availabilityImpact'] == 'HIGH' and row['cvssV3_integrityImpact'] == 'HIGH' and row['cvssV3_privilegesRequired'] == 'NONE' and row['cvssV3_userInteraction'] == 'REQUIRED'):\n",
    "        return 'HIGH'\n",
    "    elif (row['cvssV3_attackVector'] == 'NETWORK' and row['cvssV3_availabilityImpact'] == 'HIGH' and row['cvssV3_integrityImpact'] == 'HIGH' and row['cvssV3_privilegesRequired'] != 'NONE'):\n",
    "        return 'HIGH'\n",
    "    elif (row['cvssV3_attackVector'] == 'NETWORK' and row['cvssV3_integrityImpact'] == 'HIGH' and row['cvssV3_privilegesRequired'] == 'NONE'):\n",
    "        return 'HIGH'\n",
    "    elif (row['cvssV3_attackVector'] == 'NETWORK' and row['cvssV3_integrityImpact'] == 'HIGH' and row['cvssV3_privilegesRequired'] != 'NONE'):\n",
    "        return 'HIGH'\n",
    "    elif (row['cvssV3_availabilityImpact'] != 'HIGH' and row['cvssV3_confidentialityImpact'] != 'LOW' and row['cvssV3_userInteraction'] == 'NONE' and row['cvssV3_integrityImpact'] != 'HIGH' and row['cvssV3_privilegesRequired'] == 'NONE'):\n",
    "        return 'HIGH'\n",
    "    elif (row['cvssV3_confidentialityImpact'] != 'LOW' and row['cvssV3_userInteraction'] == 'REQUIRED' and row['cvssV3_integrityImpact'] != 'HIGH' and row['cvssV3_privilegesRequired'] == 'NONE'):\n",
    "        return 'LOW'        \n",
    "    elif (row['cvssV3_confidentialityImpact'] == 'LOW' and row['cvssV3_integrityImpact'] != 'HIGH' and row['cvssV3_privilegesRequired'] == 'NONE'):\n",
    "        return 'LOW'         \n",
    "    elif (row['cvssV3_confidentialityImpact'] != 'LOW' and row['cvssV3_integrityImpact'] != 'HIGH' and row['cvssV3_privilegesRequired'] != 'NONE'):\n",
    "        return 'LOW'            \n",
    "    elif (row['cvssV3_confidentialityImpact'] != 'LOW' and row['cvssV3_integrityImpact'] != 'HIGH' and row['cvssV3_privilegesRequired'] != 'NONE'):\n",
    "        return 'LOW'\n",
    "    else:\n",
    "        return 'LOW'\n",
    "\n",
    "#severity = calculateSeverityScore(cvss3_df.iloc[0]['cvssV3_baseScore'])\n",
    "#severity\n",
    "\n",
    "cvssv3_model_df['Severity_Score'] = cvssv3_model_df.apply(lambda row: calculateSeverityScore(row),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateSeverity(row):\n",
    "   try:\n",
    "        if (row['Severity_Score'] == \"CRITICAL\" and row['Super_Severity_Score'] == 1):\n",
    "                return 'CRITICAL'\n",
    "        elif (row['Severity_Score'] == \"CRITICAL\" and row['Super_Severity_Score'] == 0):\n",
    "                return 'HIGH'  \n",
    "        else:\n",
    "            return  row['Severity_Score']\n",
    "   except AttributeError:\n",
    "      return 0      \n",
    "cvssv3_model_df['New_Severity_Score'] = cvssv3_model_df.apply(lambda row: updateSeverity(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_to_num = {'CRITICAL': 1,\n",
    "                    'HIGH': 2,\n",
    "                    'LOW': 3}\n",
    "cvssv3_model_df['Severity_Score_Num'] = cvssv3_model_df['New_Severity_Score'].map(severity_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_model_df['Severity_Score_Num'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_model_df.rename(columns = {'New_Severity_Score':'Severity_Score_Text'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_model_df.rename(columns = {'Severity_Score_Num':'New_Severity_Score'}, inplace = True)\n",
    "Y = cvssv3_model_df['New_Severity_Score']\n",
    "Y.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"features.csv\", index=False, encoding='utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.to_csv(\"classes.csv\",index=False,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.head\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data set into 70% training and 30% test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "X_train.describe().T\n",
    "X_test.describe().T\n",
    "pandas_profiling.ProfileReport(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42) # 70% training and 30% test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.70)]\n",
    "\n",
    "\n",
    "# Drop features \n",
    "X_train.drop(to_drop, axis=1, inplace=True)\n",
    "X_test.drop(to_drop,axis=1, inplace=True)\n",
    "X.drop(to_drop,axis=1, inplace=True)\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\",splitter=\"best\",max_depth=7,random_state=42)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_indicator = clf.decision_path(X_train)\n",
    "node_indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = clf.tree_.node_count\n",
    "n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_indicator = clf.decision_path(X_train)\n",
    "n_nodes = clf.tree_.node_count\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "leave_id = clf.apply(X_train)\n",
    "\n",
    "\n",
    "def value2prob(value):\n",
    "    return value / value.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def print_condition(sample_id):\n",
    "    print(\"WHEN\", end=' ')\n",
    "    node_index = node_indicator.indices[node_indicator.indptr[sample_id]:\n",
    "                                        node_indicator.indptr[sample_id + 1]]\n",
    "    \n",
    "    for n, node_id in enumerate(node_index):\n",
    "        if leave_id[sample_id] == node_id:\n",
    "            values = clf.tree_.value[node_id]\n",
    "            probs = value2prob(values)\n",
    "            print('THEN Y={} (probability={}) (values={})'.format(\n",
    "                probs.argmax(), probs.max(), values))\n",
    "            continue\n",
    "        if n > 0:\n",
    "            print('&& ', end='')\n",
    "        if (X_train[sample_id, feature[node_id]] <= threshold[node_id]):\n",
    "            threshold_sign = \"<=\"\n",
    "        else:\n",
    "            threshold_sign = \">\"\n",
    "        if feature[node_id] != _tree.TREE_UNDEFINED:\n",
    "            print(\n",
    "                \"%s %s %s\" % (\n",
    "                    feature_names[feature[node_id]],\n",
    "                    #Xtrain[sample_id,feature[node_id]] # actual value\n",
    "                    threshold_sign,\n",
    "                    threshold[node_id]),\n",
    "                end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_condition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "def print_score(clf, X_train, X_test, y_train, y_test, train=True):\n",
    "    '''\n",
    "    v0.1 Follow the scikit learn library format in terms of input\n",
    "    print the accuracy score, classification report and confusion matrix of classifier\n",
    "    '''\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    if train:\n",
    "        '''\n",
    "        training performance\n",
    "        '''\n",
    "        res = clf.predict(X_train)\n",
    "        print(\"Train Result:\\n\")\n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_train, \n",
    "                                                                res)))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_train, \n",
    "                                                                            res)))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_train, \n",
    "                                                                  res)))\n",
    "        print(\"ROC AUC: {0:.4f}\\n\".format(roc_auc_score(lb.transform(y_train), \n",
    "                                                      lb.transform(res))))\n",
    "\n",
    "        #res = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        #print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n",
    "        #print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))\n",
    "        \n",
    "    elif train==False:\n",
    "        '''\n",
    "        test performance\n",
    "        '''\n",
    "        res_test = clf.predict(X_test)\n",
    "        print(\"Test Result:\\n\")        \n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, \n",
    "                                                                res_test)))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, \n",
    "                                                                            res_test)))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, \n",
    "                                                                  res_test)))   \n",
    "        print(\"ROC AUC: {0:.4f}\\n\".format(roc_auc_score(lb.transform(y_test), \n",
    "                                                      lb.transform(res_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_score(clf, X_train, X_test, y_train, y_test, train=True)\n",
    "print_score(clf, X_train, X_test, y_train, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = clf.tree_.node_count\n",
    "children_left = clf.tree_.children_left\n",
    "children_right = clf.tree_.children_right\n",
    "feature = clf.tree_.feature\n",
    "threshold = clf.tree_.threshold\n",
    "n_nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The score method returns the accuracy of the model\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_depth_range = list(range(1, 10))# List to store the average RMSE for each value of max_depth:\n",
    "accuracy = []\n",
    "for depth in max_depth_range:\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth = depth, \n",
    "                             random_state = 0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    accuracy.append(score)\n",
    "    #print(score)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree.export import export_text\n",
    "tree_rules = export_text(clf, feature_names = list(X.columns))\n",
    "tree_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(tree, feature_names):\n",
    "        left      = tree.tree_.children_left\n",
    "        right     = tree.tree_.children_right\n",
    "        threshold = tree.tree_.threshold\n",
    "        features  = [feature_names[i] for i in tree.tree_.feature]\n",
    "        value = tree.tree_.value\n",
    "\n",
    "        def recurse(left, right, threshold, features, node):\n",
    "                if (threshold[node] != -2):\n",
    "                        print(\"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\")\n",
    "                        if left[node] != -1:\n",
    "                                recurse (left, right, threshold, features,left[node])\n",
    "                        print(\"} else {\")\n",
    "                        if right[node] != -1:\n",
    "                                recurse (left, right, threshold, features,right[node])\n",
    "                        print(\"}\")\n",
    "                else:\n",
    "                        print(\"return \" + str(value[node]))\n",
    "\n",
    "        recurse(left, right, threshold, features, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_code(clf,X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skompiler import skompile\n",
    "skompile(clf.predict).to('python/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [feature_names[i] \n",
    "                    if i != _tree.TREE_UNDEFINED else \"undefined!\" \n",
    "                    for i in tree_.feature]\n",
    "    print(\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"    \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print(\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print(\"{}return {}\".format(indent, np.argmax(tree_.value[node])))\n",
    "\n",
    "    recurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_to_code(clf,X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_decision_tree(tree, feature_names=None, offset_unit='    '):\n",
    "    '''Plots textual representation of rules of a decision tree\n",
    "    tree: scikit-learn representation of tree\n",
    "    feature_names: list of feature names. They are set to f1,f2,f3,... if not specified\n",
    "    offset_unit: a string of offset of the conditional block'''\n",
    "\n",
    "    left      = tree.tree_.children_left\n",
    "    right     = tree.tree_.children_right\n",
    "    threshold = tree.tree_.threshold\n",
    "    value = tree.tree_.value\n",
    "    if feature_names is None:\n",
    "        features  = ['f%d'%i for i in tree.tree_.feature]\n",
    "    else:\n",
    "        features  = [feature_names[i] for i in tree.tree_.feature]        \n",
    "\n",
    "    def recurse(left, right, threshold, features, node, depth=0):\n",
    "            offset = offset_unit*depth\n",
    "            if (threshold[node] != -2):\n",
    "                    print(offset+\"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\")\n",
    "                    if left[node] != -1:\n",
    "                            recurse (left, right, threshold, features,left[node],depth+1)\n",
    "                    print(offset+\"} else {\")\n",
    "                    if right[node] != -1:\n",
    "                            recurse (left, right, threshold, features,right[node],depth+1)\n",
    "                    print(offset+\"}\")\n",
    "            else:\n",
    "                    print(offset+\"return \" + str(value[node]))\n",
    "\n",
    "    recurse(left, right, threshold, features, 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_decision_tree(clf,X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "plt.figure(figsize=(40,20))  # customize according to the size of your tree\n",
    "_ = tree.plot_tree(clf, feature_names = X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children_left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y['CVE_ID'] = df['data_meta_ID']\n",
    "#Y.index = df['data_meta_ID']\n",
    "classes = pd.DataFrame(Y)\n",
    "#Y['CVE_ID'] = df['data_meta_ID']\n",
    "#Y.size\n",
    "classes['CVE_ID'] = df['data_meta_ID']\n",
    "classes.head\n",
    "classes.to_csv(\"classes.csv\",index=False,encoding='utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.drop(to_drop,axis=1, inplace=True)\n",
    "X.shape\n",
    "#X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = clf.predict(X)\n",
    "ynew.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_new = pd.DataFrame(ynew)\n",
    "#Y['CVE_ID'] = df['data_meta_ID']\n",
    "#Y.size\n",
    "classes_new['CVE_ID'] = df['data_meta_ID']\n",
    "classes_new.head\n",
    "classes_new.to_csv(\"classes_new.csv\",index=False,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classes_new.rename(columns = {0:'Severity_Score'}, inplace = True)\n",
    "classes_new.columns\n",
    "classes_new['Severity_Score'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vendor = pd.read_csv(\"D:\\\\repos\\\\APDSProject\\\\MLTuning\\\\datacollection\\\\vendor_cve_map.csv\")\n",
    "vendor.rename(columns = {'CVE ID':'data_meta_ID'}, inplace = True)\n",
    "vendor.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vendor = pd.read_csv(\"D:\\\\repos\\\\APDSProject\\\\MLTuning\\\\datacleanup\\\\vendor_cve_map.csv\")\n",
    "\n",
    "df_outer = pd.merge(df, vendor, on='data_meta_ID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer.drop_duplicates(subset=['data_meta_ID'])\n",
    "df_outer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outer['Vendor'].head\n",
    "#df_outer['# of Exploits'].value_counts()\n",
    "# of Exploits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}