{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600328556028",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "import sys\n",
    "print(sys.version)\n",
    "print(sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\repos\\\\APDSProject\\\\MLTuning\\\\datacleanup\\\\cvss_final_dataset.csv\")\n",
    "df.head()\n",
    "df.shape\n",
    "#df.info()\n",
    "#df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "remove_list = ['timestamp','data_type','data_format', 'data_version','data_meta_ASSIGNER','cvssV3_version','cvssV3_vectorString','cvssV2_version','cvssV2_vectorString']\n",
    "\n",
    "df.drop(remove_list,axis = 1, inplace = True)\n",
    "df.info\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CVSS3 Data Frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "cvss3_features = ['cvssV3_attackVector', 'cvssV3_attackComplexity', 'cvssV3_privilegesRequired', 'cvssV3_userInteraction', 'cvssV3_scope','cvssV3_confidentialityImpact', 'cvssV3_integrityImpact','cvssV3_availabilityImpact', 'cvssV3_baseScore', 'cvssV3_baseSeverity',      'baseMetricV3_exploitabilityScore', 'baseMetricV3_impactScore', ]\n",
    "\n",
    "cvss3_df = df[cvss3_features]\n",
    "\n",
    "cvss3_df.columns\n",
    "cvss3_df.info\n",
    "cvss3_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the numerical and categorical columns from CVSS Version 3 Featue Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_numerical_col = list(cvss3_df.describe().columns)\n",
    "cvssv3_categorical_col = list(set(cvss3_df.columns).difference(cvssv3_numerical_col))\n",
    "\n",
    "cvssv3_numerical_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvss3_df[cvssv3_numerical_col].corr()\n",
    "plt.figure(figsize=(24,8))\n",
    "sns.heatmap(cvss3_df[cvssv3_numerical_col].corr(), annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_categorical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "cvss3_df.describe()\n",
    "cvss3_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the features for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cvssv3_model_df= cvss3_df[cvssv3_categorical_col]\n",
    "cvssv3_model_df.columns\n",
    "\n",
    "cvssv3_model_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvssv3_model_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform One Hot Encoding\n",
    "# https://towardsdatascience.com/encoding-categorical-features-21a2651a065c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v3_model = pd.get_dummies(cvssv3_model_df[cvssv3_categorical_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "df_v3_model.describe()\n",
    "df_v3_model.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,8))\n",
    "sns.heatmap(df_v3_model.corr(), annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = df_v3_model.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.70)]\n",
    "\n",
    "\n",
    "# Drop features \n",
    "df_v3_model.drop(to_drop, axis=1, inplace=True)\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.concat([df['cvssV3_baseScore'], df_v3_model], axis=1)\n",
    "X = df_v3_model\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,8))\n",
    "\n",
    "# Mask for the upper triangle\n",
    "mask = np.zeros_like(X.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "#cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "cmap = sns.light_palette((210, 90, 60), input=\"husl\")\n",
    "\n",
    "# Heatmap with mask\n",
    "sns.heatmap(X.corr(), mask=mask, cmap=cmap, annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correlatedColumns = []\n",
    "corr = X.corr()\n",
    "indices = corr.index\n",
    "columns = corr.columns\n",
    "posthreshold = 0.7\n",
    "negthreshold = -0.7\n",
    "\n",
    "for c in columns:\n",
    "    for r in indices:\n",
    "        if c != r and (corr[c][r] > posthreshold or corr[c][r] < negthreshold):\n",
    "            print(\"column \"  + c , \"  row \" + r + \"  val \" + str(corr[c][r]) )\n",
    "            correlatedColumns.append({\"column\" : c , \"row\" : r , \"val\" :corr[c][r] })\n",
    "            \n",
    "\n",
    "print(correlatedColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculateSeverityScore(baseScore):\n",
    "    #baseScore = score\n",
    "    if baseScore < 10.0 and baseScore > 8.0:\n",
    "        return 'CRITICAL'\n",
    "    elif baseScore < 8.0 and baseScore > 6.0:\n",
    "        return 'HIGH'\n",
    "    elif baseScore < 6.0 and baseScore > 4.0:\n",
    "        return 'MEDIUM'\n",
    "    else:\n",
    "        return 'LOW'\n",
    "\n",
    "#severity = calculateSeverityScore(cvss3_df.iloc[0]['cvssV3_baseScore'])\n",
    "#severity\n",
    "\n",
    "cvss3_df['Severity_Score'] = cvss3_df['cvssV3_baseScore'].apply(calculateSeverityScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvss3_df['Severity_Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_to_num = {'CRITICAL': 1,\n",
    "                    'HIGH': 2,\n",
    "                    'MEDIUM': 3,\n",
    "                    'LOW': 4}\n",
    "cvss3_df['Severity_Score_Num'] = cvss3_df['Severity_Score'].map(severity_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvss3_df['Severity_Score_Num'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvss3_df.rename(columns = {'Severity_Score':'Severity_Score_Text'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvss3_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvss3_df.rename(columns = {'Severity_Score_Num':'Severity_Score'}, inplace = True)\n",
    "Y = cvss3_df['Severity_Score']\n",
    "Y.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"features.csv\", index=False, encoding='utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.to_csv(\"classes.csv\",index=False,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['CVSS3_Base_Score']=cvss3_df['cvssV3_baseScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"features_vineet.csv\", index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data set into 70% training and 30% test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree.export import export_text\n",
    "tree_rules = export_text(clf, feature_names = list(X.columns))\n",
    "tree_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(tree, feature_names):\n",
    "        left      = tree.tree_.children_left\n",
    "        right     = tree.tree_.children_right\n",
    "        threshold = tree.tree_.threshold\n",
    "        features  = [feature_names[i] for i in tree.tree_.feature]\n",
    "        value = tree.tree_.value\n",
    "\n",
    "        def recurse(left, right, threshold, features, node):\n",
    "                if (threshold[node] != -2):\n",
    "                        print (\"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\")\n",
    "                        if left[node] != -1:\n",
    "                                recurse (left, right, threshold, features,left[node])\n",
    "                        print (\"} else {\")\n",
    "                        if right[node] != -1:\n",
    "                                recurse (left, right, threshold, features,right[node])\n",
    "                        print (\"}\")\n",
    "                else:\n",
    "                        print (\"return \" + str(value[node]))\n",
    "\n",
    "        recurse(left, right, threshold, features, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    get_code(clf,list(X.columns)) | samp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train, clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "def print_score(clf, X_train, X_test, y_train, y_test, train=True):\n",
    "    '''\n",
    "    v0.1 Follow the scikit learn library format in terms of input\n",
    "    print the accuracy score, classification report and confusion matrix of classifier\n",
    "    '''\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    if train:\n",
    "        '''\n",
    "        training performance\n",
    "        '''\n",
    "        res = clf.predict(X_train)\n",
    "        print(\"Train Result:\\n\")\n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_train, \n",
    "                                                                res)))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_train, \n",
    "                                                                            res)))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_train, \n",
    "                                                                  res)))\n",
    "        print(\"ROC AUC: {0:.4f}\\n\".format(roc_auc_score(lb.transform(y_train), \n",
    "                                                      lb.transform(res))))\n",
    "\n",
    "        #res = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        #print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n",
    "        #print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))\n",
    "        \n",
    "    elif train==False:\n",
    "        '''\n",
    "        test performance\n",
    "        '''\n",
    "        res_test = clf.predict(X_test)\n",
    "        print(\"Test Result:\\n\")        \n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, \n",
    "                                                                res_test)))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, \n",
    "                                                                            res_test)))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, \n",
    "                                                                  res_test)))   \n",
    "        print(\"ROC AUC: {0:.4f}\\n\".format(roc_auc_score(lb.transform(y_test), \n",
    "                                                      lb.transform(res_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_score(clf, X_train, X_test, y_train, y_test, train=True)\n",
    "print_score(clf, X_train, X_test, y_train, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "text_representation = tree.export_text(clf)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://www.cvedetails.com/vulnerability-list/vendor_id-1/product_id-4'\n",
    "html = requests.get(url).content\n",
    "df_list = pd.read_html(html)\n",
    "df = df_list[-1]\n",
    "#print(df)\n",
    "new_df = df.iloc[::2]\n",
    "new_df.to_csv('my data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}